####################################################################
## Script to preprocess peptide-level quants to reduce the number of shared peptides
## Author: Ayse Dincer 09/08/2021

# The script takes as input the preprocessed peptide-level quants processed_peptide_quants.tsv generated by the script preprocess_PSM_files.py

# The script carries out the following preprocessing steps:
# Define a bipartite graph of proteins and peptides
# Identify pairs of proteins mapping to the exact same list of peptides and eliminate one of these proteins randomly
# Modify the tsv file to remove these duplicate proteins

#The script records the results as a tab seperated file processed_peptide_quants_duplicate_proteins_eliminated.tsv
####################################################################

import numpy as np
import pandas as pd
from functools import reduce
import os

#Read the peptide quants file
data_df = pd.read_csv('processed_peptide_quants.tsv', sep = '\t', index_col = 0)
data_df.index = np.arange(data_df.shape[0])
print("Data df ", data_df.shape)
print("Data df ", data_df)

print("Defining bipartite graph of proteins and peptides...")

#Define bipartite graph
all_proteins = [p for p in data_df['Protein'].values]
all_proteins = [p.split(';') for p in all_proteins]
all_unique_proteins = np.unique([item for sublist in all_proteins for item in sublist])
print("No of all proteins ", len(all_proteins))
print("No of unique proteins ", len(all_unique_proteins))

all_peptides_per_protein = []

for p in range(len(all_unique_proteins)):
	if p % 10000 == 0:
		print(p)
	protein = all_unique_proteins[p]
	#print(protein)
	protein_list = all_unique_proteins[p]
	sub_indices = [i for i, protein_list in enumerate(all_proteins) if protein in protein_list] 
	#print(sub_indices)
	all_peptides_per_protein.append(sub_indices)

print("Removing duplicate peptides...")
list_of_proteins_to_remove = []

#Identify the duplicate proteins
all_proteins_sorted = [x for _,x in sorted(zip(all_peptides_per_protein, all_unique_proteins))]
all_peptides_per_protein_sorted = sorted(all_peptides_per_protein)
indices_to_remove = [i for i in range(len(all_peptides_per_protein_sorted)) if i != 0 and all_peptides_per_protein_sorted[i] == all_peptides_per_protein_sorted[i-1]]
print("No of eliminated proteins  ", len(indices_to_remove))
list_of_proteins_to_remove = np.array(all_proteins_sorted)[np.array(indices_to_remove).astype(int)]

#Remove all the duplicate proteins from the data frame
new_protein_names_list = []
for i in range(len(all_proteins)):
	if i % 10000 == 0:
		print(i)
	proteins = all_proteins[i]

	#Eliminate duplicate proteins
	new_protein_names = [p for p in proteins if p not in list_of_proteins_to_remove]
	new_protein_names_list.append(';'.join(new_protein_names))

#Replace the protein names
data_df['Protein'] = new_protein_names_list
print("Final df  ", data_df.shape)
print("Final df  ", data_df.iloc[:, :3])

#Record results 
print("Number of peptides ", data_df.shape[0])
print("Number of unique peptides ", len(np.where(np.array([len(p.split(';')) for p in data_df['Protein'].values]) == 1)[0]))
data_df.to_csv('processed_peptide_quants_duplicate_proteins_eliminated.tsv', sep = '\t')
print(data_df)

